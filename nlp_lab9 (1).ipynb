{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBwhzstsS2fY"
      },
      "outputs": [],
      "source": [
        "#The process of classifying words into their parts of speech and labeling them accordingly is known as part-of-speech tagging, or simply POS-tagging.\n",
        "\n",
        "#steps\n",
        "#Tokenize text (word_tokenize)\n",
        "#apply pos_tag to above step that is nltk.pos_tag(tokenize_text)\n",
        "#NLTK POS tagger is used to assign grammatical information of each word of the sentence. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applications:  information retrieval, parsing, Text to Speech (TTS) applications, information extraction, linguistic research for corpora."
      ],
      "metadata": {
        "id": "tvf8G-areWTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Techniques\n",
        "1. Rule-based POS tagging: The rule-based POS tagging models apply a set of handwritten rules and use contextual information to assign POS tags to words.\n",
        "2. Transformation Based Tagging:  The transformation-based approaches use a pre-defined set of handcrafted rules as well as automatically induced rules that are generated during training.\n",
        "3.deep learning models: Various Deep learning models have been used for POS tagging such as Meta-BiLSTM \n",
        "4.Stochastic (Probabilistic) tagging: A stochastic approach includes frequency, probability or statistics."
      ],
      "metadata": {
        "id": "3Wmv4tS6e5Tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HFsoMmVwe2EP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunking(shallow parsing)- process to take small pieces of information and group them into large units. The primary use of Chunking is making groups of “noun phrases.”\n",
        "It is used to add structure to the sentence by following POS tagging combined with regular expressions. \n",
        "The resulted group of words are called “chunks\".\n",
        "Chunking is used for entity detection."
      ],
      "metadata": {
        "id": "p4tvufwPWr7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaOMwvQMXSQs",
        "outputId": "c3618efe-9426-4f9a-b6eb-33d86f4b9281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk import RegexpParser\n",
        "text =\"Boult Audio headphone had many defects and. Highly dissatisfied with the company.\".split()\n",
        "print(\"After Split:\",text)\n",
        "tokens_tag = pos_tag(text)\n",
        "print(\"After Token:\",tokens_tag)\n",
        "patterns= \"\"\"mychunk:{<NN.?>*<VBD.?>*<JJ.?>*<CC>?}\"\"\"\n",
        "chunker = RegexpParser(patterns)\n",
        "print(\"After Regex:\",chunker)\n",
        "output = chunker.parse(tokens_tag)\n",
        "print(\"After Chunking\",output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4wdUXAvWpMT",
        "outputId": "2fdb341d-df46-4a29-9407-7d92a15f9da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Split: ['Boult', 'Audio', 'headphone', 'had', 'many', 'defects', 'and.', 'Highly', 'dissatisfied', 'with', 'the', 'company.']\n",
            "After Token: [('Boult', 'NNP'), ('Audio', 'NNP'), ('headphone', 'NN'), ('had', 'VBD'), ('many', 'JJ'), ('defects', 'NNS'), ('and.', 'VBP'), ('Highly', 'NNP'), ('dissatisfied', 'VBD'), ('with', 'IN'), ('the', 'DT'), ('company.', 'NN')]\n",
            "After Regex: chunk.RegexpParser with 1 stages:\n",
            "RegexpChunkParser with 1 rules:\n",
            "       <ChunkRule: '<NN.?>*<VBD.?>*<JJ.?>*<CC>?'>\n",
            "After Chunking (S\n",
            "  (mychunk Boult/NNP Audio/NNP headphone/NN had/VBD many/JJ)\n",
            "  (mychunk defects/NNS)\n",
            "  and./VBP\n",
            "  (mychunk Highly/NNP dissatisfied/VBD)\n",
            "  with/IN\n",
            "  the/DT\n",
            "  (mychunk company./NN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK POS Tags Examples are as below:\n",
        "\n",
        "Abbreviation\tMeaning\n",
        "CC\tcoordinating conjunction\n",
        "CD\tcardinal digit\n",
        "DT\tdeterminer\n",
        "EX\texistential there\n",
        "FW\tforeign word\n",
        "IN\tpreposition/subordinating conjunction\n",
        "JJ\tThis NLTK POS Tag is an adjective (large)\n",
        "JJR\tadjective, comparative (larger)\n",
        "JJS\tadjective, superlative (largest)\n",
        "LS\tlist market\n",
        "MD\tmodal (could, will)\n",
        "NN\tnoun, singular (cat, tree)\n",
        "NNS\tnoun plural (desks)\n",
        "NNP\tproper noun, singular (sarah)\n",
        "NNPS\tproper noun, plural (indians or americans)\n",
        "PDT\tpredeterminer (all, both, half)\n",
        "POS\tpossessive ending (parent\\ ‘s)\n",
        "PRP\tpersonal pronoun (hers, herself, him, himself)\n",
        "PRP$\tpossessive pronoun (her, his, mine, my, our )\n",
        "RB\tadverb (occasionally, swiftly)\n",
        "RBR\tadverb, comparative (greater)\n",
        "RBS\tadverb, superlative (biggest)\n",
        "RP\tparticle (about)\n",
        "TO\tinfinite marker (to)\n",
        "UH\tinterjection (goodbye)\n",
        "VB\tverb (ask)\n",
        "VBG\tverb gerund (judging)\n",
        "VBD\tverb past tense (pleaded)\n",
        "VBN\tverb past participle (reunified)\n",
        "VBP\tverb, present tense not 3rd person singular(wrap)\n",
        "VBZ\tverb, present tense with 3rd person singular (bases)\n",
        "WDT\twh-determiner (that, what)\n",
        "WP\twh- pronoun (who)\n",
        "WRB\twh- adverb (how)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pnYznHybYFX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a2NnaQBbiqe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting tags- crucial for text classification \n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "text = \"Boult Audio headphone had many defects and. Highly dissatisfied with the company.Other Boult products are quite fine. \"\n",
        "lower_case = text.lower()\n",
        "tokens = nltk.word_tokenize(lower_case)\n",
        "tags = nltk.pos_tag(tokens)\n",
        "counts = Counter( tag for word,  tag in tags)\n",
        "print(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhcL_fJwZh_A",
        "outputId": "f2616fb9-737c-4a1d-fad1-d666d8e812a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'NN': 5, 'JJ': 3, 'NNS': 2, '.': 2, 'RB': 2, 'VBD': 1, 'CC': 1, 'IN': 1, 'DT': 1, 'VBP': 1})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocations are the pairs of words occurring together many times in a document.\n",
        "It is calculated by the number of those pair occurring together to the overall word count of the document.\n",
        "Types :\n",
        "Bigrams\n",
        "Trigrams \n",
        "They are useful in text-based sentimental analysis."
      ],
      "metadata": {
        "id": "n6Vpa4Jbc9Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bigrams\n",
        "Tokens = nltk.word_tokenize(text)\n",
        "output = list(nltk.bigrams(Tokens))\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWi0ZgzbaZDm",
        "outputId": "5a7d0b85-0b10-43b2-a411-6e3e8c56491b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Boult', 'Audio'), ('Audio', 'headphone'), ('headphone', 'had'), ('had', 'many'), ('many', 'defects'), ('defects', 'and'), ('and', '.'), ('.', 'Highly'), ('Highly', 'dissatisfied'), ('dissatisfied', 'with'), ('with', 'the'), ('the', 'company.Other'), ('company.Other', 'Boult'), ('Boult', 'products'), ('products', 'are'), ('are', 'quite'), ('quite', 'fine'), ('fine', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trigrams\n",
        "Tokens = nltk.word_tokenize(text)\n",
        "output = list(nltk.trigrams(Tokens))\n",
        "print(output)"
      ],
      "metadata": {
        "id": "JSNsDXs2azFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5076c3c-ce25-4a92-c4ab-0e8afdb3557e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Boult', 'Audio', 'headphone'), ('Audio', 'headphone', 'had'), ('headphone', 'had', 'many'), ('had', 'many', 'defects'), ('many', 'defects', 'and'), ('defects', 'and', '.'), ('and', '.', 'Highly'), ('.', 'Highly', 'dissatisfied'), ('Highly', 'dissatisfied', 'with'), ('dissatisfied', 'with', 'the'), ('with', 'the', 'company.Other'), ('the', 'company.Other', 'Boult'), ('company.Other', 'Boult', 'products'), ('Boult', 'products', 'are'), ('products', 'are', 'quite'), ('are', 'quite', 'fine'), ('quite', 'fine', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing HMM with Viterbi Algorithm \n",
        "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states—called the Viterbi path—that results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM)."
      ],
      "metadata": {
        "id": "OklQV9X2fkmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint, time\n",
        " \n",
        "#download the treebank corpus from nltk\n",
        "nltk.download('treebank')\n",
        " \n",
        "#download the universal tagset from nltk\n",
        "nltk.download('universal_tagset')\n",
        " \n",
        "# reading the Treebank tagged sentences\n",
        "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
        " \n",
        "#print the first two sentences along with tags\n",
        "print(nltk_data[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYKDV9CsfwWB",
        "outputId": "c536a07b-c707-4d64-f9df-6e56b8813114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print each word with its respective tag for first two sentences\n",
        "for sent in nltk_data[:2]:\n",
        "  for tuple in sent:\n",
        "    print(tuple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuC6FFyYf5RQ",
        "outputId": "93677ad3-5cdf-4b81-b630-a3238976fbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Pierre', 'NOUN')\n",
            "('Vinken', 'NOUN')\n",
            "(',', '.')\n",
            "('61', 'NUM')\n",
            "('years', 'NOUN')\n",
            "('old', 'ADJ')\n",
            "(',', '.')\n",
            "('will', 'VERB')\n",
            "('join', 'VERB')\n",
            "('the', 'DET')\n",
            "('board', 'NOUN')\n",
            "('as', 'ADP')\n",
            "('a', 'DET')\n",
            "('nonexecutive', 'ADJ')\n",
            "('director', 'NOUN')\n",
            "('Nov.', 'NOUN')\n",
            "('29', 'NUM')\n",
            "('.', '.')\n",
            "('Mr.', 'NOUN')\n",
            "('Vinken', 'NOUN')\n",
            "('is', 'VERB')\n",
            "('chairman', 'NOUN')\n",
            "('of', 'ADP')\n",
            "('Elsevier', 'NOUN')\n",
            "('N.V.', 'NOUN')\n",
            "(',', '.')\n",
            "('the', 'DET')\n",
            "('Dutch', 'NOUN')\n",
            "('publishing', 'VERB')\n",
            "('group', 'NOUN')\n",
            "('.', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# split data into training and validation set in the ratio 80:20\n",
        "train_set,test_set =train_test_split(nltk_data,train_size=0.80,test_size=0.20,random_state = 101)"
      ],
      "metadata": {
        "id": "5PAZutZTgBHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create list of train and test tagged words\n",
        "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
        "test_tagged_words = [ tup for sent in test_set for tup in sent ]\n",
        "print(len(train_tagged_words))\n",
        "print(len(test_tagged_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktyMglOXgFYX",
        "outputId": "edf65c82-620d-43f3-9c11-a8e6f8296271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80310\n",
            "20366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# check some of the tagged words.\n",
        "train_tagged_words[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcMVD6VegJFS",
        "outputId": "aa1f2442-29cb-4960-844b-b55f4176ba2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Drink', 'NOUN'),\n",
              " ('Carrier', 'NOUN'),\n",
              " ('Competes', 'VERB'),\n",
              " ('With', 'ADP'),\n",
              " ('Cartons', 'NOUN')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use set datatype to check how many unique tags are present in training data\n",
        "tags = {tag for word,tag in train_tagged_words}\n",
        "print(len(tags))\n",
        "print(tags)\n",
        " \n",
        "# check total words in vocabulary\n",
        "vocab = {word for word,tag in train_tagged_words}"
      ],
      "metadata": {
        "id": "O3EekTg8gN5j",
        "outputId": "a9d1a0a5-88a0-428a-a980-c0531c99f7c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "{'CONJ', 'ADV', 'PRON', 'ADP', 'NOUN', '.', 'X', 'NUM', 'ADJ', 'VERB', 'DET', 'PRT'}\n"
          ]
        }
      ]
    }
  ]
}